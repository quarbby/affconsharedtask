{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "review.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quarbby/affconsharedtask/blob/master/review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UryVeM2ehg9O",
        "colab_type": "text"
      },
      "source": [
        "# Semi-supervised learning techniques\n",
        "\n",
        "#### Self-labeling\n",
        "Seems like the simplest method, where the model first trains on the small amount of labeled data, then generates labels for the unlabeled data, which is then used as further training data. Only the unlabeled data for which the model is confident in will be used for training.\n",
        "\n",
        "#### Virtual Adversarial Training (VAT)\n",
        "Maybe not exactly applicable, but here, the training seems to be done with all the data being augmented with adversarial noise (essentially, but the math eludes me), where the labeled data uses their label as a benchmark and unlabeled data uses the prediction on the unperturbed images as a benchmark. This means that the model is learning to predict consistently regardless of the perturbation in the direction the model is most sensitive to. Can (probably) be applied to the word embeddings in this case.\n",
        "\n",
        "(was understood from an article summarising the paper, so may be an oversimplification)\n",
        "\n",
        "paper: https://arxiv.org/pdf/1704.03976.pdf\n",
        "\n",
        "reference article(s): https://medium.com/inside-machine-learning/placeholder-3557ebb3d470\n",
        "\n",
        "\n",
        "#### Unsupervised Data Augmentation (UDA)\n",
        "\n",
        "Tries to make the model more consistent in its predictions by adding targeted data augmentations generally aimed at supervised learning as a means of, then using Training Signal Annealing (TSA) to help prevent overfitting on the labeled data while remaining underfitted on the unlabeled data. The specific augmentations they use for text are Backtranslation, where we pass the original text through a separate translator network, then translating it back to english, which paraphrases the sentence while retaining the same meaning (if the translator is adequate), and TF-IDF based word replacing, where unimportant words with lower TF-IDF score will have a higher chance of being replaced. The authors of the paper reason that TF-IDF is more suitable as a method for topic classification where certain key words are more important to identifying a topic than others as back-translation does not guarantee any words being kept. \n",
        "\n",
        "TSA is a training technique where if the confidence of the model on a labeled example reaches a certain threshold, the example will be dropped from training. This threshold also increases as the training progresses, and the paper tests three definitions of the threshold, log, linear and exponential.\n",
        "\n",
        "This paper seems to be the current SOTA, although MixMatch is comparable. The techniques for this and MixMatch also seem to be compatible \n",
        "\n",
        "paper: https://arxiv.org/pdf/1904.12848v4.pdf\n",
        "\n",
        "reference article(s): https://mlexplained.com/2019/06/02/papers-dissected-mixmatch-a-holistic-approach-to-semi-supervised-learning-and-unsupervised-data-augmentation-explained/\n",
        "\n",
        "https://ai.googleblog.com/2019/07/advancing-semi-supervised-learning-with.html\n",
        "\n",
        "\n",
        "#### MixMatch\n",
        "\n",
        "The main paper is on images, but the techniques might be able to be applied to the word embeddings? They average the predictions over multiple augmentations of unlabeled data, before sharpening it to use as a means of labeling the unlabeled data. They also generate augmentations for the labeled data. After this process, they perform MixUp using both unlabeled and labeled data with each as a base to produce 2 more sets of training data, one based on labeled and the other based on unlabeled data. MixUp is a data augmentation technique that seems to basically be generating an interpolation between 2 examples(both the data and the label).\n",
        "\n",
        "paper: https://arxiv.org/pdf/1905.02249.pdf\n",
        "\n",
        "reference article(s): https://mlexplained.com/2019/06/02/papers-dissected-mixmatch-a-holistic-approach-to-semi-supervised-learning-and-unsupervised-data-augmentation-explained/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi_t1Cwy4a_d",
        "colab_type": "text"
      },
      "source": [
        "# Networks considered\n",
        "\n",
        "Since SOTA are all variations on the transformer architecture, I only look at those\n",
        "Probably use https://github.com/huggingface/transformers as a library, since pytorch seems more convenient to code\n",
        "\n",
        "#### BERT\n",
        "Pros:\n",
        "Seems to have extensive documentation/usage examples, making it easier to use\n",
        "Cons:\n",
        "No longer SOTA, mask token bias\n",
        "\n",
        "#### XLNet\n",
        "Pros:\n",
        "SOTA, fancy permutation based token reveal learning instead of masking tokens\n",
        "Cons:\n",
        "Newer, less documentation\n",
        "\n",
        "(work in progress)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR0xE4X64RyZ",
        "colab_type": "text"
      },
      "source": [
        "#Random stuff\n",
        "\n",
        "####KL Divergence\n",
        "A way of measuring the loss of information when modeling one probability distribution with another\n",
        "\n",
        "#### Regularisation\n",
        "A means to prevent overfitting by penalising more complex models"
      ]
    }
  ]
}